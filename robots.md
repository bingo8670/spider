网络爬虫的尺寸

| 小规模，数据量小，爬取速度不敏感，Requests库，90% | 中规模，数据规模较大，爬取速度敏感，Scrapy库 | 大规模，搜索引擎，爬取速度关键，定制开发 |
| ------------------------------------------------- | -------------------------------------------- | ---------------------------------------- |
| 爬取网页，玩转网页                                | 爬取网站，爬取系列网站                       | 爬取全网                                 |

网络爬虫的问题：

- 受限于编写水平和目的，网络爬虫将会为web服务器带来巨大的资源开销；
- 服务器上的数据游产权归属；获取数据后牟利有法律风险；
- 个人隐私泄露问题；

***

网络爬虫的限制

- 来源审查：判断User-Agent进行限制；检查来访HTTP协议头的User-Agent域，只响应浏览器或友好爬虫的访问。
- 发布公告(Robots协议)：告知所有爬虫网站的爬取策略，要求爬虫遵守。

------

Robots协议：

- Robots Exclusion Standard，网络爬虫排除标准；

- 作用：网站告知网络爬虫哪些页面可以抓取，哪些不行；

- 形式：在网站根目录下的robots.txt文件；

- 京东  Https://www.jd.com/robots.txt   （*代表所有，/代表根目录）

- 百度 Https://www.baidu.com/robots.txt

- 新浪Http://www.sina.com.cn/robots.txt

- QQHttps://www.qq.com/robots.txt

- QQ新闻Https://news.qq.com/robots.txt

  